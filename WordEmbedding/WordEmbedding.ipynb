{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DirPpath = Path(os.path.abspath('')).parent # Fetching the current directory path - Specific for ipynb file - For .py: Path(os.path.dirname(os.path.realpath(__file__)).replace(\"\\\\\", \"/\"))\n",
    "\n",
    "PledgesCsvPath = str(DirPpath.absolute()) + \"/CleanedData.csv\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PledgesDf = pd.read_csv(PledgesCsvPath, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Achieve sustainable and flexible solutions for multimodal transport and develop policies to protect natural heritage and biodiversity, respecting the socio-cultural authenticity of host communities.  CNA Turismo e Commercio, over the three-year period (between autumn 2022 and throughout 2023), will organize training seminars for businesses - with the involvement of public and private stakeholders - aimed at the implementation of concrete solutions for the development of good practices for a supply of multimodal transport and protocols for the respect and protection of the natural heritage and biodiversity.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def first_clean(text):\n",
    "    return \" \".join(text.split()).replace(\"_x000D_\",\"\")\n",
    "\n",
    "first_clean(PledgesDf.iloc[3,1]) # Delete the returns from excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'achieve sustainable and flexible solutions for multimodal transport and develop policies to protect natural heritage and biodiversity respecting the socio cultural authenticity of host communities cna turismo e commercio over the three year period between autumn and throughout will organize training seminars for businesses with the involvement of public and private stakeholders aimed at the implementation of concrete solutions for the development of good practices for a supply of multimodal transport and protocols for the respect and protection of the natural heritage and biodiversity'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess(text):\n",
    "    text = text.lower() # Lowercase all the characters from the string\n",
    "    text = text.strip() # Remove the leading and trailing whitespaces\n",
    "    text = re.compile('<.*?>').sub('', text)\n",
    "    text = re.compile('[%s]' % re.escape(string.punctuation)).sub(' ', text) # Removing Punctuation\n",
    "    text = re.sub(r'\\[[0-9]*\\]', ' ', text)\n",
    "    text = re.sub(r'[^\\w\\s]', '', str(text)) # Remove non alphanumeric characters\n",
    "    text = re.sub(r'\\d', '', text) # Removing digits\n",
    "    text = re.sub(r'\\s+', ' ', str(text).strip()) # Replacing \"double, triple, etc\" whitespaces by one\n",
    "    return text\n",
    "\n",
    "preprocess(first_clean(PledgesDf.iloc[3,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'achieve sustainable flexible solutions multimodal transport develop policies protect natural heritage biodiversity respecting socio cultural authenticity host communities cna turismo e commercio three year period autumn throughout organize training seminars businesses involvement public private stakeholders aimed implementation concrete solutions development good practices supply multimodal transport protocols respect protection natural heritage biodiversity'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def stopword(string):\n",
    "    a = [i for i in string.split() if i not in stopwords.words('english')]\n",
    "    return ' '.join(a)\n",
    "\n",
    "stopword(preprocess(first_clean(PledgesDf.iloc[3,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'achieve sustainable flexible solution multimodal transport develop policy protect natural heritage biodiversity respect socio cultural authenticity host community cna turismo e commercio three year period autumn throughout organize training seminar business involvement public private stakeholder aim implementation concrete solution development good practice supply multimodal transport protocol respect protection natural heritage biodiversity'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LEMMATIZATION\n",
    "# Initialize the lemmatizer\n",
    "wl = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "# This is a helper function to map NTLK position tags\n",
    "def get_wordnet_pos(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "\n",
    "\n",
    "# Tokenize the sentence\n",
    "def lemmatizer(string):\n",
    "    word_pos_tags = nltk.pos_tag(nltk.word_tokenize(string))  # Get position tags\n",
    "    a = [wl.lemmatize(tag[0], get_wordnet_pos(tag[1])) for idx, tag in\n",
    "         enumerate(word_pos_tags)]  # Map the position tag and lemmatize the word/token\n",
    "    return \" \".join(a)\n",
    "\n",
    "lemmatizer(stopword(preprocess(first_clean(PledgesDf.iloc[3,1]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(text):\n",
    "\n",
    "    global n\n",
    "    n = n +1\n",
    "    \n",
    "    print(\"**************\")\n",
    "    print(\"n is : \")\n",
    "    print(n)\n",
    "    print(\"length of the text is : \")\n",
    "    print(len(first_clean(text)))\n",
    "    return lemmatizer(stopword(preprocess(first_clean(text))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin pre-processing\n",
      "**************\n",
      "n is : \n",
      "1\n",
      "length of the text is : \n",
      "1461\n",
      "**************\n",
      "n is : \n",
      "2\n",
      "length of the text is : \n",
      "953\n",
      "**************\n",
      "n is : \n",
      "3\n",
      "length of the text is : \n",
      "273\n",
      "**************\n",
      "n is : \n",
      "4\n",
      "length of the text is : \n",
      "613\n",
      "**************\n",
      "n is : \n",
      "5\n",
      "length of the text is : \n",
      "249\n",
      "**************\n",
      "n is : \n",
      "6\n",
      "length of the text is : \n",
      "304\n",
      "**************\n",
      "n is : \n",
      "7\n",
      "length of the text is : \n",
      "1125\n",
      "**************\n",
      "n is : \n",
      "8\n",
      "length of the text is : \n",
      "640\n",
      "**************\n",
      "n is : \n",
      "9\n",
      "length of the text is : \n",
      "352\n",
      "**************\n",
      "n is : \n",
      "10\n",
      "length of the text is : \n",
      "130\n",
      "**************\n",
      "n is : \n",
      "11\n",
      "length of the text is : \n",
      "2676\n",
      "**************\n",
      "n is : \n",
      "12\n",
      "length of the text is : \n",
      "266\n",
      "**************\n",
      "n is : \n",
      "13\n",
      "length of the text is : \n",
      "2442\n",
      "**************\n",
      "n is : \n",
      "14\n",
      "length of the text is : \n",
      "361\n",
      "**************\n",
      "n is : \n",
      "15\n",
      "length of the text is : \n",
      "2586\n",
      "**************\n",
      "n is : \n",
      "16\n",
      "length of the text is : \n",
      "1031\n",
      "**************\n",
      "n is : \n",
      "17\n",
      "length of the text is : \n",
      "1046\n",
      "**************\n",
      "n is : \n",
      "18\n",
      "length of the text is : \n",
      "867\n",
      "**************\n",
      "n is : \n",
      "19\n",
      "length of the text is : \n",
      "1105\n",
      "**************\n",
      "n is : \n",
      "20\n",
      "length of the text is : \n",
      "244\n",
      "**************\n",
      "n is : \n",
      "21\n",
      "length of the text is : \n",
      "465\n",
      "**************\n",
      "n is : \n",
      "22\n",
      "length of the text is : \n",
      "1265\n",
      "**************\n",
      "n is : \n",
      "23\n",
      "length of the text is : \n",
      "1713\n",
      "**************\n",
      "n is : \n",
      "24\n",
      "length of the text is : \n",
      "1629\n",
      "**************\n",
      "n is : \n",
      "25\n",
      "length of the text is : \n",
      "4320\n",
      "**************\n",
      "n is : \n",
      "26\n",
      "length of the text is : \n",
      "221\n",
      "**************\n",
      "n is : \n",
      "27\n",
      "length of the text is : \n",
      "1076\n",
      "**************\n",
      "n is : \n",
      "28\n",
      "length of the text is : \n",
      "2529\n",
      "**************\n",
      "n is : \n",
      "29\n",
      "length of the text is : \n",
      "1797\n",
      "**************\n",
      "n is : \n",
      "30\n",
      "length of the text is : \n",
      "551\n",
      "**************\n",
      "n is : \n",
      "31\n",
      "length of the text is : \n",
      "2210\n",
      "**************\n",
      "n is : \n",
      "32\n",
      "length of the text is : \n",
      "479\n",
      "**************\n",
      "n is : \n",
      "33\n",
      "length of the text is : \n",
      "210\n",
      "**************\n",
      "n is : \n",
      "34\n",
      "length of the text is : \n",
      "1666\n",
      "**************\n",
      "n is : \n",
      "35\n",
      "length of the text is : \n",
      "460\n",
      "**************\n",
      "n is : \n",
      "36\n",
      "length of the text is : \n",
      "1064\n",
      "**************\n",
      "n is : \n",
      "37\n",
      "length of the text is : \n",
      "2138\n",
      "**************\n",
      "n is : \n",
      "38\n",
      "length of the text is : \n",
      "330\n",
      "**************\n",
      "n is : \n",
      "39\n",
      "length of the text is : \n",
      "397\n",
      "**************\n",
      "n is : \n",
      "40\n",
      "length of the text is : \n",
      "153\n",
      "**************\n",
      "n is : \n",
      "41\n",
      "length of the text is : \n",
      "936\n",
      "**************\n",
      "n is : \n",
      "42\n",
      "length of the text is : \n",
      "895\n",
      "**************\n",
      "n is : \n",
      "43\n",
      "length of the text is : \n",
      "685\n",
      "**************\n",
      "n is : \n",
      "44\n",
      "length of the text is : \n",
      "1165\n",
      "**************\n",
      "n is : \n",
      "45\n",
      "length of the text is : \n",
      "1337\n",
      "**************\n",
      "n is : \n",
      "46\n",
      "length of the text is : \n",
      "194\n",
      "**************\n",
      "n is : \n",
      "47\n",
      "length of the text is : \n",
      "2335\n",
      "**************\n",
      "n is : \n",
      "48\n",
      "length of the text is : \n",
      "243\n",
      "**************\n",
      "n is : \n",
      "49\n",
      "length of the text is : \n",
      "204\n",
      "**************\n",
      "n is : \n",
      "50\n",
      "length of the text is : \n",
      "324\n",
      "**************\n",
      "n is : \n",
      "51\n",
      "length of the text is : \n",
      "553\n",
      "**************\n",
      "n is : \n",
      "52\n",
      "length of the text is : \n",
      "1934\n",
      "**************\n",
      "n is : \n",
      "53\n",
      "length of the text is : \n",
      "144\n",
      "**************\n",
      "n is : \n",
      "54\n",
      "length of the text is : \n",
      "1517\n",
      "**************\n",
      "n is : \n",
      "55\n",
      "length of the text is : \n",
      "518\n",
      "**************\n",
      "n is : \n",
      "56\n",
      "length of the text is : \n",
      "297\n",
      "**************\n",
      "n is : \n",
      "57\n",
      "length of the text is : \n",
      "586\n",
      "**************\n",
      "n is : \n",
      "58\n",
      "length of the text is : \n",
      "1709\n",
      "**************\n",
      "n is : \n",
      "59\n",
      "length of the text is : \n",
      "2018\n",
      "**************\n",
      "n is : \n",
      "60\n",
      "length of the text is : \n",
      "2185\n",
      "**************\n",
      "n is : \n",
      "61\n",
      "length of the text is : \n",
      "804\n",
      "**************\n",
      "n is : \n",
      "62\n",
      "length of the text is : \n",
      "1226\n",
      "**************\n",
      "n is : \n",
      "63\n",
      "length of the text is : \n",
      "2476\n",
      "**************\n",
      "n is : \n",
      "64\n",
      "length of the text is : \n",
      "668\n",
      "**************\n",
      "n is : \n",
      "65\n",
      "length of the text is : \n",
      "1598\n",
      "**************\n",
      "n is : \n",
      "66\n",
      "length of the text is : \n",
      "2977\n",
      "**************\n",
      "n is : \n",
      "67\n",
      "length of the text is : \n",
      "2097\n",
      "**************\n",
      "n is : \n",
      "68\n",
      "length of the text is : \n",
      "425\n",
      "**************\n",
      "n is : \n",
      "69\n",
      "length of the text is : \n",
      "1499\n",
      "**************\n",
      "n is : \n",
      "70\n",
      "length of the text is : \n",
      "1608\n",
      "**************\n",
      "n is : \n",
      "71\n",
      "length of the text is : \n",
      "440\n",
      "**************\n",
      "n is : \n",
      "72\n",
      "length of the text is : \n",
      "1456\n",
      "**************\n",
      "n is : \n",
      "73\n",
      "length of the text is : \n",
      "1358\n",
      "**************\n",
      "n is : \n",
      "74\n",
      "length of the text is : \n",
      "465\n",
      "**************\n",
      "n is : \n",
      "75\n",
      "length of the text is : \n",
      "1186\n",
      "**************\n",
      "n is : \n",
      "76\n",
      "length of the text is : \n",
      "481\n",
      "**************\n",
      "n is : \n",
      "77\n",
      "length of the text is : \n",
      "1074\n",
      "**************\n",
      "n is : \n",
      "78\n",
      "length of the text is : \n",
      "1736\n",
      "**************\n",
      "n is : \n",
      "79\n",
      "length of the text is : \n",
      "4543\n",
      "**************\n",
      "n is : \n",
      "80\n",
      "length of the text is : \n",
      "453\n",
      "**************\n",
      "n is : \n",
      "81\n",
      "length of the text is : \n",
      "1714\n",
      "**************\n",
      "n is : \n",
      "82\n",
      "length of the text is : \n",
      "2104\n",
      "**************\n",
      "n is : \n",
      "83\n",
      "length of the text is : \n",
      "727\n",
      "**************\n",
      "n is : \n",
      "84\n",
      "length of the text is : \n",
      "1291\n",
      "**************\n",
      "n is : \n",
      "85\n",
      "length of the text is : \n",
      "598\n",
      "**************\n",
      "n is : \n",
      "86\n",
      "length of the text is : \n",
      "410\n",
      "**************\n",
      "n is : \n",
      "87\n",
      "length of the text is : \n",
      "580\n",
      "**************\n",
      "n is : \n",
      "88\n",
      "length of the text is : \n",
      "1048\n",
      "**************\n",
      "n is : \n",
      "89\n",
      "length of the text is : \n",
      "1042\n",
      "**************\n",
      "n is : \n",
      "90\n",
      "length of the text is : \n",
      "1450\n",
      "**************\n",
      "n is : \n",
      "91\n",
      "length of the text is : \n",
      "481\n",
      "**************\n",
      "n is : \n",
      "92\n",
      "length of the text is : \n",
      "4911\n",
      "**************\n",
      "n is : \n",
      "93\n",
      "length of the text is : \n",
      "1051\n",
      "**************\n",
      "n is : \n",
      "94\n",
      "length of the text is : \n",
      "488\n",
      "**************\n",
      "n is : \n",
      "95\n",
      "length of the text is : \n",
      "486\n",
      "**************\n",
      "n is : \n",
      "96\n",
      "length of the text is : \n",
      "427\n",
      "**************\n",
      "n is : \n",
      "97\n",
      "length of the text is : \n",
      "1498\n",
      "**************\n",
      "n is : \n",
      "98\n",
      "length of the text is : \n",
      "2349\n",
      "**************\n",
      "n is : \n",
      "99\n",
      "length of the text is : \n",
      "916\n",
      "**************\n",
      "n is : \n",
      "100\n",
      "length of the text is : \n",
      "494\n",
      "**************\n",
      "n is : \n",
      "101\n",
      "length of the text is : \n",
      "1743\n",
      "**************\n",
      "n is : \n",
      "102\n",
      "length of the text is : \n",
      "999\n",
      "**************\n",
      "n is : \n",
      "103\n",
      "length of the text is : \n",
      "537\n",
      "**************\n",
      "n is : \n",
      "104\n",
      "length of the text is : \n",
      "356\n",
      "**************\n",
      "n is : \n",
      "105\n",
      "length of the text is : \n",
      "2784\n",
      "**************\n",
      "n is : \n",
      "106\n",
      "length of the text is : \n",
      "230\n",
      "**************\n",
      "n is : \n",
      "107\n",
      "length of the text is : \n",
      "229\n",
      "**************\n",
      "n is : \n",
      "108\n",
      "length of the text is : \n",
      "764\n",
      "**************\n",
      "n is : \n",
      "109\n",
      "length of the text is : \n",
      "1315\n",
      "**************\n",
      "n is : \n",
      "110\n",
      "length of the text is : \n",
      "730\n",
      "**************\n",
      "n is : \n",
      "111\n",
      "length of the text is : \n",
      "751\n",
      "**************\n",
      "n is : \n",
      "112\n",
      "length of the text is : \n",
      "374\n",
      "**************\n",
      "n is : \n",
      "113\n",
      "length of the text is : \n",
      "956\n",
      "**************\n",
      "n is : \n",
      "114\n",
      "length of the text is : \n",
      "252\n",
      "**************\n",
      "n is : \n",
      "115\n",
      "length of the text is : \n",
      "699\n",
      "**************\n",
      "n is : \n",
      "116\n",
      "length of the text is : \n",
      "619\n",
      "**************\n",
      "n is : \n",
      "117\n",
      "length of the text is : \n",
      "1330\n",
      "**************\n",
      "n is : \n",
      "118\n",
      "length of the text is : \n",
      "301\n",
      "**************\n",
      "n is : \n",
      "119\n",
      "length of the text is : \n",
      "1281\n",
      "**************\n",
      "n is : \n",
      "120\n",
      "length of the text is : \n",
      "996\n",
      "**************\n",
      "n is : \n",
      "121\n",
      "length of the text is : \n",
      "98\n",
      "**************\n",
      "n is : \n",
      "122\n",
      "length of the text is : \n",
      "599\n",
      "**************\n",
      "n is : \n",
      "123\n",
      "length of the text is : \n",
      "315\n",
      "**************\n",
      "n is : \n",
      "124\n",
      "length of the text is : \n",
      "1959\n",
      "**************\n",
      "n is : \n",
      "125\n",
      "length of the text is : \n",
      "2364\n",
      "**************\n",
      "n is : \n",
      "126\n",
      "length of the text is : \n",
      "885\n",
      "**************\n",
      "n is : \n",
      "127\n",
      "length of the text is : \n",
      "544\n",
      "**************\n",
      "n is : \n",
      "128\n",
      "length of the text is : \n",
      "806\n",
      "**************\n",
      "n is : \n",
      "129\n",
      "length of the text is : \n",
      "1415\n",
      "**************\n",
      "n is : \n",
      "130\n",
      "length of the text is : \n",
      "296\n",
      "**************\n",
      "n is : \n",
      "131\n",
      "length of the text is : \n",
      "1027\n",
      "**************\n",
      "n is : \n",
      "132\n",
      "length of the text is : \n",
      "679\n",
      "**************\n",
      "n is : \n",
      "133\n",
      "length of the text is : \n",
      "1581\n",
      "**************\n",
      "n is : \n",
      "134\n",
      "length of the text is : \n",
      "597\n",
      "**************\n",
      "n is : \n",
      "135\n",
      "length of the text is : \n",
      "184\n",
      "**************\n",
      "n is : \n",
      "136\n",
      "length of the text is : \n",
      "399\n",
      "**************\n",
      "n is : \n",
      "137\n",
      "length of the text is : \n",
      "480\n",
      "**************\n",
      "n is : \n",
      "138\n",
      "length of the text is : \n",
      "435\n",
      "**************\n",
      "n is : \n",
      "139\n",
      "length of the text is : \n",
      "185\n",
      "**************\n",
      "n is : \n",
      "140\n",
      "length of the text is : \n",
      "3921\n",
      "**************\n",
      "n is : \n",
      "141\n",
      "length of the text is : \n",
      "406\n",
      "**************\n",
      "n is : \n",
      "142\n",
      "length of the text is : \n",
      "382\n",
      "**************\n",
      "n is : \n",
      "143\n",
      "length of the text is : \n",
      "356\n",
      "**************\n",
      "n is : \n",
      "144\n",
      "length of the text is : \n",
      "1375\n",
      "**************\n",
      "n is : \n",
      "145\n",
      "length of the text is : \n",
      "365\n",
      "**************\n",
      "n is : \n",
      "146\n",
      "length of the text is : \n",
      "1251\n",
      "**************\n",
      "n is : \n",
      "147\n",
      "length of the text is : \n",
      "1282\n",
      "**************\n",
      "n is : \n",
      "148\n",
      "length of the text is : \n",
      "2257\n",
      "**************\n",
      "n is : \n",
      "149\n",
      "length of the text is : \n",
      "964\n",
      "**************\n",
      "n is : \n",
      "150\n",
      "length of the text is : \n",
      "970\n",
      "**************\n",
      "n is : \n",
      "151\n",
      "length of the text is : \n",
      "404\n",
      "**************\n",
      "n is : \n",
      "152\n",
      "length of the text is : \n",
      "1047\n",
      "**************\n",
      "n is : \n",
      "153\n",
      "length of the text is : \n",
      "925\n",
      "**************\n",
      "n is : \n",
      "154\n",
      "length of the text is : \n",
      "141\n",
      "**************\n",
      "n is : \n",
      "155\n",
      "length of the text is : \n",
      "1328\n",
      "**************\n",
      "n is : \n",
      "156\n",
      "length of the text is : \n",
      "573\n",
      "**************\n",
      "n is : \n",
      "157\n",
      "length of the text is : \n",
      "1069\n",
      "**************\n",
      "n is : \n",
      "158\n",
      "length of the text is : \n",
      "339\n",
      "**************\n",
      "n is : \n",
      "159\n",
      "length of the text is : \n",
      "1324\n",
      "**************\n",
      "n is : \n",
      "160\n",
      "length of the text is : \n",
      "473\n",
      "**************\n",
      "n is : \n",
      "161\n",
      "length of the text is : \n",
      "1159\n",
      "**************\n",
      "n is : \n",
      "162\n",
      "length of the text is : \n",
      "649\n",
      "**************\n",
      "n is : \n",
      "163\n",
      "length of the text is : \n",
      "681\n",
      "**************\n",
      "n is : \n",
      "164\n",
      "length of the text is : \n",
      "1057\n",
      "**************\n",
      "n is : \n",
      "165\n",
      "length of the text is : \n",
      "313\n",
      "**************\n",
      "n is : \n",
      "166\n",
      "length of the text is : \n",
      "1031\n",
      "**************\n",
      "n is : \n",
      "167\n",
      "length of the text is : \n",
      "553\n",
      "**************\n",
      "n is : \n",
      "168\n",
      "length of the text is : \n",
      "812\n",
      "**************\n",
      "n is : \n",
      "169\n",
      "length of the text is : \n",
      "923\n",
      "**************\n",
      "n is : \n",
      "170\n",
      "length of the text is : \n",
      "1406\n",
      "**************\n",
      "n is : \n",
      "171\n",
      "length of the text is : \n",
      "783\n",
      "**************\n",
      "n is : \n",
      "172\n",
      "length of the text is : \n",
      "237\n",
      "**************\n",
      "n is : \n",
      "173\n",
      "length of the text is : \n",
      "585\n",
      "**************\n",
      "n is : \n",
      "174\n",
      "length of the text is : \n",
      "274\n",
      "**************\n",
      "n is : \n",
      "175\n",
      "length of the text is : \n",
      "757\n",
      "**************\n",
      "n is : \n",
      "176\n",
      "length of the text is : \n",
      "605\n",
      "**************\n",
      "n is : \n",
      "177\n",
      "length of the text is : \n",
      "351\n",
      "**************\n",
      "n is : \n",
      "178\n",
      "length of the text is : \n",
      "968\n",
      "**************\n",
      "n is : \n",
      "179\n",
      "length of the text is : \n",
      "749\n",
      "**************\n",
      "n is : \n",
      "180\n",
      "length of the text is : \n",
      "421\n",
      "**************\n",
      "n is : \n",
      "181\n",
      "length of the text is : \n",
      "555\n",
      "**************\n",
      "n is : \n",
      "182\n",
      "length of the text is : \n",
      "641\n",
      "**************\n",
      "n is : \n",
      "183\n",
      "length of the text is : \n",
      "289\n",
      "**************\n",
      "n is : \n",
      "184\n",
      "length of the text is : \n",
      "400\n",
      "**************\n",
      "n is : \n",
      "185\n",
      "length of the text is : \n",
      "547\n",
      "**************\n",
      "n is : \n",
      "186\n",
      "length of the text is : \n",
      "1903\n",
      "**************\n",
      "n is : \n",
      "187\n",
      "length of the text is : \n",
      "798\n",
      "**************\n",
      "n is : \n",
      "188\n",
      "length of the text is : \n",
      "1965\n",
      "**************\n",
      "n is : \n",
      "189\n",
      "length of the text is : \n",
      "222\n",
      "**************\n",
      "n is : \n",
      "190\n",
      "length of the text is : \n",
      "438\n",
      "**************\n",
      "n is : \n",
      "191\n",
      "length of the text is : \n",
      "837\n",
      "**************\n",
      "n is : \n",
      "192\n",
      "length of the text is : \n",
      "329\n",
      "**************\n",
      "n is : \n",
      "193\n",
      "length of the text is : \n",
      "2247\n",
      "**************\n",
      "n is : \n",
      "194\n",
      "length of the text is : \n",
      "771\n",
      "**************\n",
      "n is : \n",
      "195\n",
      "length of the text is : \n",
      "369\n",
      "**************\n",
      "n is : \n",
      "196\n",
      "length of the text is : \n",
      "472\n",
      "**************\n",
      "n is : \n",
      "197\n",
      "length of the text is : \n",
      "933\n",
      "**************\n",
      "n is : \n",
      "198\n",
      "length of the text is : \n",
      "772\n",
      "**************\n",
      "n is : \n",
      "199\n",
      "length of the text is : \n",
      "930\n",
      "**************\n",
      "n is : \n",
      "200\n",
      "length of the text is : \n",
      "1496\n",
      "**************\n",
      "n is : \n",
      "201\n",
      "length of the text is : \n",
      "1122\n",
      "**************\n",
      "n is : \n",
      "202\n",
      "length of the text is : \n",
      "863\n",
      "**************\n",
      "n is : \n",
      "203\n",
      "length of the text is : \n",
      "665\n",
      "**************\n",
      "n is : \n",
      "204\n",
      "length of the text is : \n",
      "4324\n",
      "**************\n",
      "n is : \n",
      "205\n",
      "length of the text is : \n",
      "2189\n",
      "**************\n",
      "n is : \n",
      "206\n",
      "length of the text is : \n",
      "648\n",
      "**************\n",
      "n is : \n",
      "207\n",
      "length of the text is : \n",
      "250\n",
      "**************\n",
      "n is : \n",
      "208\n",
      "length of the text is : \n",
      "670\n",
      "**************\n",
      "n is : \n",
      "209\n",
      "length of the text is : \n",
      "1218\n",
      "**************\n",
      "n is : \n",
      "210\n",
      "length of the text is : \n",
      "252\n",
      "**************\n",
      "n is : \n",
      "211\n",
      "length of the text is : \n",
      "1067\n",
      "**************\n",
      "n is : \n",
      "212\n",
      "length of the text is : \n",
      "1161\n",
      "**************\n",
      "n is : \n",
      "213\n",
      "length of the text is : \n",
      "1778\n",
      "**************\n",
      "n is : \n",
      "214\n",
      "length of the text is : \n",
      "604\n",
      "**************\n",
      "n is : \n",
      "215\n",
      "length of the text is : \n",
      "820\n",
      "**************\n",
      "n is : \n",
      "216\n",
      "length of the text is : \n",
      "314\n",
      "**************\n",
      "n is : \n",
      "217\n",
      "length of the text is : \n",
      "606\n",
      "**************\n",
      "n is : \n",
      "218\n",
      "length of the text is : \n",
      "1346\n",
      "**************\n",
      "n is : \n",
      "219\n",
      "length of the text is : \n",
      "461\n",
      "**************\n",
      "n is : \n",
      "220\n",
      "length of the text is : \n",
      "1545\n",
      "**************\n",
      "n is : \n",
      "221\n",
      "length of the text is : \n",
      "1515\n",
      "**************\n",
      "n is : \n",
      "222\n",
      "length of the text is : \n",
      "221\n",
      "**************\n",
      "n is : \n",
      "223\n",
      "length of the text is : \n",
      "908\n",
      "**************\n",
      "n is : \n",
      "224\n",
      "length of the text is : \n",
      "622\n",
      "**************\n",
      "n is : \n",
      "225\n",
      "length of the text is : \n",
      "856\n",
      "**************\n",
      "n is : \n",
      "226\n",
      "length of the text is : \n",
      "745\n",
      "**************\n",
      "n is : \n",
      "227\n",
      "length of the text is : \n",
      "2039\n",
      "**************\n",
      "n is : \n",
      "228\n",
      "length of the text is : \n",
      "2029\n",
      "**************\n",
      "n is : \n",
      "229\n",
      "length of the text is : \n",
      "1577\n",
      "**************\n",
      "n is : \n",
      "230\n",
      "length of the text is : \n",
      "540\n",
      "**************\n",
      "n is : \n",
      "231\n",
      "length of the text is : \n",
      "1110\n",
      "**************\n",
      "n is : \n",
      "232\n",
      "length of the text is : \n",
      "681\n",
      "**************\n",
      "n is : \n",
      "233\n",
      "length of the text is : \n",
      "502\n",
      "**************\n",
      "n is : \n",
      "234\n",
      "length of the text is : \n",
      "912\n",
      "**************\n",
      "n is : \n",
      "235\n",
      "length of the text is : \n",
      "847\n",
      "**************\n",
      "n is : \n",
      "236\n",
      "length of the text is : \n",
      "1496\n",
      "**************\n",
      "n is : \n",
      "237\n",
      "length of the text is : \n",
      "754\n",
      "**************\n",
      "n is : \n",
      "238\n",
      "length of the text is : \n",
      "547\n",
      "**************\n",
      "n is : \n",
      "239\n",
      "length of the text is : \n",
      "1415\n",
      "**************\n",
      "n is : \n",
      "240\n",
      "length of the text is : \n",
      "1349\n",
      "**************\n",
      "n is : \n",
      "241\n",
      "length of the text is : \n",
      "1004\n",
      "**************\n",
      "n is : \n",
      "242\n",
      "length of the text is : \n",
      "464\n",
      "**************\n",
      "n is : \n",
      "243\n",
      "length of the text is : \n",
      "443\n",
      "**************\n",
      "n is : \n",
      "244\n",
      "length of the text is : \n",
      "433\n",
      "**************\n",
      "n is : \n",
      "245\n",
      "length of the text is : \n",
      "635\n",
      "**************\n",
      "n is : \n",
      "246\n",
      "length of the text is : \n",
      "854\n",
      "**************\n",
      "n is : \n",
      "247\n",
      "length of the text is : \n",
      "788\n",
      "**************\n",
      "n is : \n",
      "248\n",
      "length of the text is : \n",
      "579\n",
      "**************\n",
      "n is : \n",
      "249\n",
      "length of the text is : \n",
      "782\n",
      "**************\n",
      "n is : \n",
      "250\n",
      "length of the text is : \n",
      "574\n",
      "**************\n",
      "n is : \n",
      "251\n",
      "length of the text is : \n",
      "3246\n",
      "**************\n",
      "n is : \n",
      "252\n",
      "length of the text is : \n",
      "1094\n",
      "end pre-processing\n"
     ]
    }
   ],
   "source": [
    "n=0\n",
    "print(\"begin pre-processing\")\n",
    "PledgesDf['clean_text'] = PledgesDf['Pledge'].apply(lambda x: preprocessing(x))\n",
    "print(\"end pre-processing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Pledge</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>HOTREC calls for a level playing field and fai...</td>\n",
       "      <td>hotrec call level play field fair competition ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Actually we as an association are still pretty...</td>\n",
       "      <td>actually association still pretty much begin d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Estonia sees the need to synchronize and harmo...</td>\n",
       "      <td>estonia see need synchronize harmonize rule sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Achieve sustainable and flexible solutions for...</td>\n",
       "      <td>achieve sustainable flexible solution multimod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>The Austrian Hoteliers Association (ÖHV) publi...</td>\n",
       "      <td>austrian hotelier association öhv publishes st...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic                                             Pledge  \\\n",
       "0      1  HOTREC calls for a level playing field and fai...   \n",
       "1      1  Actually we as an association are still pretty...   \n",
       "2      1  Estonia sees the need to synchronize and harmo...   \n",
       "3      2  Achieve sustainable and flexible solutions for...   \n",
       "5      3  The Austrian Hoteliers Association (ÖHV) publi...   \n",
       "\n",
       "                                          clean_text  \n",
       "0  hotrec call level play field fair competition ...  \n",
       "1  actually association still pretty much begin d...  \n",
       "2  estonia see need synchronize harmonize rule sh...  \n",
       "3  achieve sustainable flexible solution multimod...  \n",
       "5  austrian hotelier association öhv publishes st...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PledgesDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tourism',\n",
       " 'sustainable',\n",
       " 'destination',\n",
       " 'development',\n",
       " 'data',\n",
       " 'support',\n",
       " 'project',\n",
       " 'sustainability',\n",
       " 'sector',\n",
       " 'tourist',\n",
       " 'develop',\n",
       " 'digital',\n",
       " 'use',\n",
       " 'eu',\n",
       " 'work',\n",
       " 'action',\n",
       " 'local',\n",
       " 'service',\n",
       " 'green',\n",
       " 'plan',\n",
       " 'city',\n",
       " 'target',\n",
       " 'year',\n",
       " 'european',\n",
       " 'strategy',\n",
       " 'travel',\n",
       " 'also',\n",
       " 'regional',\n",
       " 'share',\n",
       " 'least']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(\" \".join(PledgesDf['clean_text']).split()).value_counts()[:30].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = [nltk.word_tokenize(i) for i in PledgesDf[\"clean_text\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3267"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_freq = {}\n",
    "for sent in tokens:\n",
    "    for i in sent:\n",
    "\n",
    "        if i not in word_freq.keys():\n",
    "            word_freq[i] = 1\n",
    "        else:\n",
    "            word_freq[i] += 1\n",
    "len(word_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tourism',\n",
       " 'sustainable',\n",
       " 'destination',\n",
       " 'development',\n",
       " 'data',\n",
       " 'support',\n",
       " 'project',\n",
       " 'sustainability',\n",
       " 'sector',\n",
       " 'tourist']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(word_freq, key=word_freq.get, reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidfvectorizer = TfidfVectorizer(analyzer='word',stop_words= 'english')\n",
    "\n",
    "tfidf_wm = tfidfvectorizer.fit_transform(PledgesDf[\"clean_text\"])\n",
    "\n",
    "tfidf_tokens = tfidfvectorizer.get_feature_names_out()\n",
    "df_tfidfvect = pd.DataFrame(data = tfidf_wm.toarray(),columns = tfidf_tokens)\n",
    "\n",
    "print(\"\\nTD-IDF Vectorizer\\n\")\n",
    "print(df_tfidfvect)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualiser les mots avec PCA ou t-sn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn import decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = model.wv.vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tsnescatterplot(model, word, list_names):\n",
    "    \"\"\" Plot in seaborn the results from the t-SNE dimensionality reduction algorithm of the vectors of a query word,\n",
    "    its list of most similar words, and a list of words.\n",
    "    \"\"\"\n",
    "    arrays = np.empty((0, 100), dtype='f')\n",
    "    word_labels = [word]\n",
    "    color_list  = ['red']\n",
    "\n",
    "    # adds the vector of the query word\n",
    "    arrays = np.append(arrays, model.wv.__getitem__([word]), axis=0)\n",
    "    \n",
    "    # gets list of most similar words\n",
    "    close_words = model.wv.most_similar([word])\n",
    "    \n",
    "    # adds the vector for each of the closest words to the array\n",
    "    for wrd_score in close_words:\n",
    "        wrd_vector = model.wv.__getitem__([wrd_score[0]])\n",
    "        word_labels.append(wrd_score[0])\n",
    "        color_list.append('blue')\n",
    "        arrays = np.append(arrays, wrd_vector, axis=0)\n",
    "    \n",
    "    # adds the vector for each of the words from list_names to the array\n",
    "    for wrd in list_names:\n",
    "        wrd_vector = model.wv.__getitem__([wrd])\n",
    "        word_labels.append(wrd)\n",
    "        color_list.append('green')\n",
    "        arrays = np.append(arrays, wrd_vector, axis=0)\n",
    "        \n",
    "    # Reduces the dimensionality from 300 to 50 dimensions with PCA\n",
    "    reduc = PCA(n_components=18).fit_transform(arrays)\n",
    "    \n",
    "    # Finds t-SNE coordinates for 2 dimensions\n",
    "    np.set_printoptions(suppress=True)\n",
    "    \n",
    "    Y = TSNE(n_components=2, random_state=0, perplexity=15).fit_transform(reduc)\n",
    "    \n",
    "    # Sets everything up to plot\n",
    "    df = pd.DataFrame({'x': [x for x in Y[:, 0]],\n",
    "                       'y': [y for y in Y[:, 1]],\n",
    "                       'words': word_labels,\n",
    "                       'color': color_list})\n",
    "    \n",
    "    fig, _ = plt.subplots()\n",
    "    fig.set_size_inches(9, 9)\n",
    "    \n",
    "    # Basic plot\n",
    "    p1 = sns.regplot(data=df,\n",
    "                     x=\"x\",\n",
    "                     y=\"y\",\n",
    "                     fit_reg=False,\n",
    "                     marker=\"o\",\n",
    "                     scatter_kws={'s': 40,\n",
    "                                  'facecolors': df['color']\n",
    "                                 }\n",
    "                    )\n",
    "    \n",
    "    # Adds annotations one by one with a loop\n",
    "    for line in range(0, df.shape[0]):\n",
    "         p1.text(df[\"x\"][line],\n",
    "                 df['y'][line],\n",
    "                 '  ' + df[\"words\"][line].title(),\n",
    "                 horizontalalignment='left',\n",
    "                 verticalalignment='bottom', size='medium',\n",
    "                 color=df['color'][line],\n",
    "                 weight='normal'\n",
    "                ).set_size(15)\n",
    "\n",
    "    \n",
    "    plt.xlim(Y[:, 0].min()-50, Y[:, 0].max()+50)\n",
    "    plt.ylim(Y[:, 1].min()-50, Y[:, 1].max()+50)\n",
    "            \n",
    "    plt.title('t-SNE visualization for {}'.format(word.title()))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#building Word2Vec model\n",
    "class MeanEmbeddingVectorizer(object):\n",
    "    def __init__(self, word2vec):\n",
    "        self.word2vec = word2vec\n",
    "        # if a text is empty we should return a vector of zeros\n",
    "        # with the same dimensionality as all the other vectors\n",
    "        self.dim = len(next(iter(word2vec.values())))\n",
    "    def fit(self, X, y):\n",
    "            return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return np.array([\n",
    "            np.mean([self.word2vec[w] for w in words if w in self.word2vec]\n",
    "                    or [np.zeros(self.dim)], axis=0)\n",
    "            for words in X\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.12560223  0.23184161  0.15681297 ... -0.2639868   0.09877244\n",
      "  -0.09417447]\n",
      " [-0.14467603  0.2658919   0.18210404 ... -0.3050768   0.11311968\n",
      "  -0.10659759]\n",
      " [-0.133623    0.25393614  0.17204833 ... -0.29037616  0.10742884\n",
      "  -0.10489351]\n",
      " ...\n",
      " [-0.17307088  0.32190362  0.21772222 ... -0.36497992  0.13521887\n",
      "  -0.12980379]\n",
      " [-0.15961476  0.29458204  0.20010252 ... -0.3362451   0.12484045\n",
      "  -0.11860909]\n",
      " [-0.14230888  0.2624757   0.18064186 ... -0.30391672  0.11278331\n",
      "  -0.10682324]]\n"
     ]
    }
   ],
   "source": [
    "w2v = dict(zip(model.wv.index_to_key, model.wv.vectors))\n",
    "modelw = MeanEmbeddingVectorizer(w2v)\n",
    "\n",
    "# converting text to numerical data using Word2Vec\n",
    "vectors_w2v = modelw.transform(tokens)\n",
    "\n",
    "print(vectors_w2v)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualiser les documents avec PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv2 = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv2.most_similar(positive=[\"hotrec\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.06275298  0.01186308 -0.01152449 ... -0.01491957 -0.0153909\n",
      "  -0.01533057]\n",
      " [-0.01571469 -0.00829576 -0.00121289 ... -0.00275593  0.01694754\n",
      "  -0.01605253]\n",
      " [-0.02050312  0.01648125  0.00840877 ... -0.03087616  0.02504554\n",
      "   0.02424622]\n",
      " ...\n",
      " [-0.05052965  0.01950734 -0.00666775 ... -0.02613797  0.05620015\n",
      "   0.00589074]\n",
      " [-0.01669904  0.01115993 -0.00876993 ... -0.03272089  0.10013308\n",
      "  -0.01204444]\n",
      " [-0.04008275  0.00388049 -0.01519181 ... -0.0157918   0.02797811\n",
      "   0.02045738]]\n"
     ]
    }
   ],
   "source": [
    "w2v2 = dict(zip(wv2.index_to_key, wv2.vectors))\n",
    "modelw2 = MeanEmbeddingVectorizer(w2v2)\n",
    "\n",
    "# converting text to numerical data using Word2Vec\n",
    "vectors_w2v2 = modelw2.transform(tokens)\n",
    "\n",
    "print(vectors_w2v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#building Word2Vec model\n",
    "class TfIdfEmbeddingVectorizer(object):\n",
    "    def __init__(self, word2vec):\n",
    "        self.word2vec = word2vec\n",
    "        # if a text is empty we should return a vector of zeros\n",
    "        # with the same dimensionality as all the other vectors\n",
    "        self.dim = len(next(iter(word2vec.values())))\n",
    "    def fit(self, X, y):\n",
    "            return self\n",
    "\n",
    "    def transform(self, X, tfidf):\n",
    "\n",
    "        DocList = []\n",
    "        i = 0\n",
    "        \n",
    "        for words in X:\n",
    "\n",
    "            WordList = []\n",
    "\n",
    "            for w in words:\n",
    "                 \n",
    "                try:\n",
    "                    if w in self.word2vec:\n",
    "                        weight = tfidf[w].iloc[i]\n",
    "                        WordList.append(self.word2vec[w] * weight)\n",
    "                    else:\n",
    "                        WordList.append(np.zeros(self.dim))\n",
    "                except:\n",
    "                    WordList.append(np.zeros(self.dim))\n",
    "\n",
    "            i+=1\n",
    "            DocList.append(np.sum(np.array(WordList), axis = 0))\n",
    "                         \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        return np.array(DocList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.27269533  0.95840782 -1.35918353 ... -0.24890735 -1.48564479\n",
      "   1.47997892]\n",
      " [-0.22334863 -0.02243496 -0.04773207 ... -0.10841947  0.03781788\n",
      "  -0.06039597]\n",
      " [-0.05090242  0.03200291  0.08663241 ... -0.21919973  0.13552499\n",
      "   0.23728875]\n",
      " ...\n",
      " [-0.83322743  0.54453521  0.23935086 ... -0.22277545  0.75050607\n",
      "   0.12778346]\n",
      " [ 0.05702502  0.29606971 -0.19303012 ... -0.82667657  2.92369157\n",
      "   0.36815178]\n",
      " [-0.450033    0.02318757 -0.25745796 ...  0.07824526  0.22051121\n",
      "   0.37442113]]\n"
     ]
    }
   ],
   "source": [
    "w2v2 = dict(zip(wv2.index_to_key, wv2.vectors))\n",
    "modelw2 = TfIdfEmbeddingVectorizer(w2v2)\n",
    "\n",
    "# converting text to numerical data using Word2Vec\n",
    "vectors_w2v2 = modelw2.transform(tokens, df_tfidfvect)\n",
    "\n",
    "print(vectors_w2v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "DocIndexV1 = pd.DataFrame(vectors_w2v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "IndexedPath = str(DirPpath.absolute()) + \"\\IndexedDataV1Tf.csv\"\n",
    "DocIndexV1.to_csv(IndexedPath)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "# Setting the model with its hyperparameters\n",
    "#model = Word2Vec(sentences = tokens, vector_size=300, min_count = 1)\n",
    "model2 = Word2Vec(sentences = tokens, vector_size=300, min_count = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KeyedVectors.load_word2vec_format(r\"C:\\Users\\ecaudron001\\Downloads\\GoogleNews-vectors-negative300.bin\",\n",
    "                                         binary = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 923 is out of bounds for axis 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[78], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m total_examples \u001b[39m=\u001b[39m model2\u001b[39m.\u001b[39mcorpus_count\n\u001b[0;32m      3\u001b[0m model2\u001b[39m.\u001b[39mbuild_vocab([\u001b[39mlist\u001b[39m(model2\u001b[39m.\u001b[39mwv\u001b[39m.\u001b[39mkey_to_index\u001b[39m.\u001b[39mkeys())], update\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m----> 4\u001b[0m model2\u001b[39m.\u001b[39;49mwv\u001b[39m.\u001b[39;49mintersect_word2vec_format(\u001b[39mr\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mC:\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39mUsers\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39mecaudron001\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39mDownloads\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39mGoogleNews-vectors-negative300.bin\u001b[39;49m\u001b[39m\"\u001b[39;49m, binary\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m      5\u001b[0m model2\u001b[39m.\u001b[39mtrain(tokens, total_examples\u001b[39m=\u001b[39mtotal_examples, epochs\u001b[39m=\u001b[39mmodel\u001b[39m.\u001b[39miter)\n",
      "File \u001b[1;32mc:\\Users\\ecaudron001\\Documents\\GitHub\\semic_pledges\\.venv\\lib\\site-packages\\gensim\\models\\keyedvectors.py:1771\u001b[0m, in \u001b[0;36mKeyedVectors.intersect_word2vec_format\u001b[1;34m(self, fname, lockf, binary, encoding, unicode_errors)\u001b[0m\n\u001b[0;32m   1769\u001b[0m             overlap_count \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m   1770\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvectors[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_index(word)] \u001b[39m=\u001b[39m weights\n\u001b[1;32m-> 1771\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvectors_lockf[\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_index(word)] \u001b[39m=\u001b[39m lockf  \u001b[39m# lock-factor: 0.0=no changes\u001b[39;00m\n\u001b[0;32m   1772\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1773\u001b[0m     \u001b[39mfor\u001b[39;00m line_no, line \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(fin):\n",
      "\u001b[1;31mIndexError\u001b[0m: index 923 is out of bounds for axis 0 with size 1"
     ]
    }
   ],
   "source": [
    "model2.build_vocab(tokens)\n",
    "total_examples = model2.corpus_count\n",
    "model2.build_vocab([list(model2.wv.key_to_index.keys())], update=True)\n",
    "model2.wv.intersect_word2vec_format(r\"C:\\Users\\ecaudron001\\Downloads\\GoogleNews-vectors-negative300.bin\", binary=True)\n",
    "model2.train(tokens, total_examples=total_examples, epochs=model.iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.wv."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
